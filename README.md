## Practical task for learning LlamaIndex

1. Install dependancies from `requirements.txt`

2. To ingest documents run `python ingest.py`

3. To run application:
    - download TinyLlama LLM into directory "./models/tinyllama.gguf" (or other model)
    - run `streamlit run app.py`